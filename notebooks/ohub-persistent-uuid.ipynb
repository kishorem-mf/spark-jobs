{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mantain a persistent UUID for groups\n",
    "\n",
    "The output from the first deduplication of records looks like\n",
    "\n",
    "|group_UUID||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"NameMatching_Notebook\")\n",
    "    .config('spark.dynamicAllocation.enabled', False)\n",
    "    .config('spark.executorEnv.PYTHON_EGG_CACHE', '/tmp')\n",
    "    .config('spark.executor.instances', 4)\n",
    "    .config('spark.executor.cores', 13)\n",
    "    .config('spark.executor.memory', '14g')\n",
    "    .config('spark.driver.memory', '7g')\n",
    "    .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as sf\n",
    "\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "Since we don't have an example of new incoming data we will separate into two dataframes. One as if it was the current data and another as the new ingestion data. I expect that there will be some overlapping operators, which is a realistic case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load current operator data and keep 5%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+------------------------+\n",
      "|ohubOperatorId                      |id                      |\n",
      "+------------------------------------+------------------------+\n",
      "|03c07042-5646-4cb6-bb59-fc4fd9a4d91a|DK~MM-INIT-OPER~O~489081|\n",
      "|03c07042-5646-4cb6-bb59-fc4fd9a4d91a|DK~mellowmessage~489081 |\n",
      "+------------------------------------+------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "operators_old_dir = 'adl://ulohubdldevne.azuredatalakestore.net/data/parquet/OPERATORS_MERGED.parquet'\n",
    "\n",
    "oprs_old = (\n",
    "    spark\n",
    "    .read.parquet(operators_old_dir)\n",
    "    .filter(sf.col('countryCode') == 'DK')\n",
    "    .sample(False, 0.05)\n",
    "    .withColumn('id', sf.explode(sf.col('refIds')))\n",
    "    .select('ohubOperatorId', 'id')\n",
    ")\n",
    "oprs_old.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get sample of source data 10%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read operators and assign id\n",
    "operators_matched_dir = 'adl://ulohubdldevne.azuredatalakestore.net/data/parquet/OPERATORS.parquet'\n",
    "\n",
    "input_oprs_raw = (\n",
    "    spark\n",
    "    .read.parquet(operators_matched_dir)\n",
    "    .filter(sf.col('COUNTRY_CODE') == 'DK')\n",
    "    .sample(False, 0.1)\n",
    ")\n",
    "    \n",
    "input_oprs = (\n",
    "    input_oprs_raw\n",
    "    .withColumn('id', sf.concat_ws('~',\n",
    "                                   sf.col('COUNTRY_CODE'),\n",
    "                                   sf.col('SOURCE'),\n",
    "                                   sf.col('REF_OPERATOR_ID'))).select('id', 'NAME_CLEANSED')\n",
    "    .repartition('id')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New and overlapping operators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known Operators: 1995\n",
      "Input Operators: 4202\n",
      "Overlapping: 202\n",
      "New: 4000\n"
     ]
    }
   ],
   "source": [
    "df = input_oprs.join(oprs_old, on='id', how='left')\n",
    "\n",
    "print('Known Operators:', oprs_old.count())\n",
    "print('Input Operators:', input_oprs_raw.count())\n",
    "print('Overlapping:', df.na.drop(subset=['ohubOperatorId']).count())\n",
    "print('New:', df.filter(sf.isnull(sf.col('ohubOperatorId'))).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Matching incoming input operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DROP_CHARS = \"\\\\\\\\!#%&()*+-/:;<=>?@\\\\^|~\\u00A8\\u00A9\\u00AA\\u00AC\\u00AD\\u00AF\\u00B0\" \\\n",
    "             \"\\u00B1\\u00B2\\u00B3\\u00B6\\u00B8\\u00B9\\u00BA\\u00BB\\u00BC\\u00BD\\u00BE\" \\\n",
    "             \"\\u2013\\u2014\\u2022\\u2026\\u20AC\\u2121\\u2122\\u2196\\u2197\\u247F\\u250A\" \\\n",
    "             \"\\u2543\\u2605\\u2606\\u3001\\u3002\\u300C\\u300D\\u300E\\u300F\\u3010\\u3011\" \\\n",
    "             \"\\uFE36\\uFF01\\uFF06\\uFF08\\uFF09\\uFF1A\\uFF1B\\uFF1F{}\\u00AE\\u00F7\\u02F1\" \\\n",
    "             \"\\u02F3\\u02F5\\u02F6\\u02F9\\u02FB\\u02FC\\u02FD\\u1BFC\\u1BFD\\u2260\\u2264\" \\\n",
    "             \"\\u2DE2\\u2DF2\\uEC66\\uEC7C\\uEC7E\\uED2B\\uED34\\uED3A\\uEDAB\\uEDFC\\uEE3B\" \\\n",
    "             \"\\uEEA3\\uEF61\\uEFA2\\uEFB0\\uEFB5\\uEFEA\\uEFED\\uFDAB\\uFFB7\\u007F\\u24D2\" \\\n",
    "             \"\\u2560\\u2623\\u263A\\u2661\\u2665\\u266A\\u2764\\uE2B1\\uFF0D\"\n",
    "REGEX = \"[{}]\".format(DROP_CHARS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**preprocess input operators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+---------------+--------------------------------------------------------------+\n",
      "|COUNTRY_CODE|string_index|id             |matching_string                                               |\n",
      "+------------+------------+---------------+--------------------------------------------------------------+\n",
      "|DK          |0           |DK~DEX~10003323|jacob kongsbak lassen københavnv flæsketorvet19 1711          |\n",
      "|DK          |1           |DK~DEX~10003413|kwik sparsupergros rebate brøndby gammelager11 2605           |\n",
      "|DK          |2           |DK~DEX~10003428|sugrolekkerland rebate tåstrup helgeshøj alle20 2630          |\n",
      "|DK          |3           |DK~DEX~10003429|nærkøb rebate vejle bugattivej18 7100                         |\n",
      "|DK          |4           |DK~DEX~10003464|dansk cater as dansk cater promotion svenstrup vidalsvej6 9230|\n",
      "+------------+------------+---------------+--------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w = Window.partitionBy('COUNTRY_CODE').orderBy(sf.asc('id'))\n",
    "\n",
    "input_oprs = (\n",
    "    input_oprs_raw\n",
    "    .na.drop(subset=['NAME_CLEANSED'])\n",
    "    # create unique ID\n",
    "    .withColumn('id', sf.concat_ws('~',\n",
    "                                   sf.col('COUNTRY_CODE'),\n",
    "                                   sf.col('SOURCE'),\n",
    "                                   sf.col('REF_OPERATOR_ID')))\n",
    "    .fillna('')\n",
    "    # create string columns to matched\n",
    "    .withColumn('matching_string',\n",
    "                sf.concat_ws(' ',\n",
    "                             sf.col('NAME_CLEANSED'),\n",
    "                             sf.col('CITY_CLEANSED'),\n",
    "                             sf.col('STREET_CLEANSED'),\n",
    "                             sf.col('ZIP_CODE_CLEANSED')))\n",
    "    .withColumn('matching_string', sf.regexp_replace('matching_string', REGEX, ''))\n",
    "    .withColumn('matching_string', sf.lower(sf.trim(sf.regexp_replace('matching_string', '\\s+', ' '))))\n",
    "    .withColumn('string_index', sf.row_number().over(w) - 1)\n",
    "    .select('COUNTRY_CODE', 'string_index', 'id', 'matching_string')\n",
    "    .repartition('id')\n",
    ")\n",
    "\n",
    "input_oprs.persist()\n",
    "input_oprs.sort('string_index').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**preprocess known operators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------------------------+------------+----------------------------+----------------------------------------------------------------------------+\n",
      "|countryCode|ohubOperatorId                      |string_index|id                          |matching_string                                                             |\n",
      "+-----------+------------------------------------+------------+----------------------------+----------------------------------------------------------------------------+\n",
      "|DK         |1a7d6ece-83dd-41d0-860a-345555629f5a|0           |DK~COMPLAINTS~2503250       |unknown                                                                     |\n",
      "|DK         |602930a3-59b9-4910-8dfa-5cf2f9dab5c3|1           |DK~COMPLAINTS~OP_USD_5067_15|                                                                            |\n",
      "|DK         |97ad8b8b-8505-42df-b691-982e1dc02752|2           |DK~DEX~10001401             |boursin fromagerie su pacy sur eure croisysureure route de st aquilin3 27120|\n",
      "|DK         |3830d696-c16f-4039-badd-6b584de1aedd|3           |DK~DEX~10001764             |unilever ireland limited dublin riverwalk national digital park20 24        |\n",
      "|DK         |833753c9-a480-40e7-a95b-2c9aa2a401d5|4           |DK~DEX~10003032             |unilever slovenija doo ljubljana leskoskova cesta9e 1000                    |\n",
      "+-----------+------------------------------------+------------+----------------------------+----------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create string name used originally for the matching\n",
    "w = Window.partitionBy('countryCode').orderBy(sf.asc('id'))\n",
    "\n",
    "oprs_old = (\n",
    "    spark\n",
    "    .read.parquet(operators_old_dir)\n",
    "    .filter(sf.col('countryCode') == 'DK')\n",
    "    .withColumn('id', sf.col('operator').getItem('operatorConcatId'))\n",
    "    .withColumn('matching_string', sf.concat_ws(' ',\n",
    "                                                sf.col('operator').getItem('nameCleansed'),\n",
    "                                                sf.col('operator').getItem('cityCleansed'),\n",
    "                                                sf.col('operator').getItem('streetCleansed'),\n",
    "                                                sf.col('operator').getItem('zipCodeCleansed')))\n",
    "    .withColumn('matching_string', sf.regexp_replace('matching_string', REGEX, ''))\n",
    "    .withColumn('matching_string', sf.lower(sf.trim(sf.regexp_replace(sf.col('matching_string'), '\\s+', ' '))))\n",
    "    .withColumn('string_index', sf.row_number().over(w) - 1)\n",
    "    .select('countryCode', 'ohubOperatorId', 'string_index', 'id', 'matching_string')\n",
    ")\n",
    "\n",
    "oprs_old.persist()\n",
    "oprs_old.sort('string_index').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Know that the format is ready to match we use the matching algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "egg_file = glob(os.path.join('..', 'dist', '*.egg'))[0]\n",
    "sc.addPyFile(egg_file)\n",
    "\n",
    "from string_matching.spark_string_matching import match_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----------+\n",
      "|  i|  j|SIMILARITY|\n",
      "+---+---+----------+\n",
      "|  0|  5|       1.0|\n",
      "|  1|  7|       1.0|\n",
      "|  2| 11|       1.0|\n",
      "|  3| 12|       1.0|\n",
      "|  4| 25|       1.0|\n",
      "+---+---+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_top = 1 # we get only the top match\n",
    "\n",
    "similarity = match_strings(\n",
    "    spark,\n",
    "    input_oprs.select('string_index', 'matching_string'),\n",
    "    df2=oprs_old.select('string_index', 'matching_string'),\n",
    "    string_column='matching_string', row_number_column='string_index',\n",
    "    n_top=n_top, threshold=0.8, n_gram=2, min_document_frequency=2, max_vocabulary_size=1500\n",
    ")\n",
    "similarity.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1252"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = (\n",
    "    input_oprs\n",
    "    .join(similarity, input_oprs['string_index'] == similarity['i'],\n",
    "    how='left').drop('string_index')\n",
    "    .selectExpr('j', 'SIMILARITY',\n",
    "                'matching_string as matching_string_input',\n",
    "                'id as id_input')\n",
    "    .join(oprs_old, sf.col('j') == oprs_old['string_index'],\n",
    "    how='left').drop('string_index')\n",
    "    .selectExpr('SIMILARITY',\n",
    "                'matching_string_input',\n",
    "                'matching_string as matching_string_old',\n",
    "                'id_input',\n",
    "                'id as id_old')\n",
    "    # we don't want matches were id and matching string remained the same\n",
    "    .withColumn('matching_string_input', sf.lower(sf.col('matching_string_input')))\n",
    "    .withColumn('matching_string_old', sf.lower(sf.col('matching_string_old')))\n",
    "    .filter((sf.col('matching_string_input') != sf.col('matching_string_old')) |\n",
    "            (sf.col('id_input') != sf.col('id_old')))\n",
    ")\n",
    "matches.persist()\n",
    "matches.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------------------------------+---------------------------------------------------------+-------------------------+-----------------------+\n",
      "|SIMILARITY|matching_string_input                     |matching_string_old                                      |id_input                 |id_old                 |\n",
      "+----------+------------------------------------------+---------------------------------------------------------+-------------------------+-----------------------+\n",
      "|0.9053102 |center bageriet tune tune centret1 b 4030 |helle bjergtrup center bageriet tune tune centret1 b 4030|DK~DEX~10344242          |DK~DEX~10344243        |\n",
      "|1.0       |antropologerne                            |antropologerne                                           |DK~MM-INIT-OPER~O~1468874|DK~WEBUPDATER~O~1468874|\n",
      "|0.93287545|ågård efterskole ågård kirkebakken 13 6040|ågård efterskole egtved kirkebakken13 ågård 6040         |DK~mellowmessage~486452  |DK~DEX~1004121735      |\n",
      "+----------+------------------------------------------+---------------------------------------------------------+-------------------------+-----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matches.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------+-------------------+--------+------+\n",
      "|SIMILARITY|matching_string_input|matching_string_old|id_input|id_old|\n",
      "+----------+---------------------+-------------------+--------+------+\n",
      "+----------+---------------------+-------------------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# thsi should be empty\n",
    "matches.filter(sf.col('id_input') == sf.col('id_old')).show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
