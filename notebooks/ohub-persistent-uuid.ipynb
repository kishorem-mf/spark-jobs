{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mantain a persistent UUID for groups\n",
    "\n",
    "The output from the first deduplication of records looks like\n",
    "\n",
    "|group_UUID||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"NameMatching_Notebook\")\n",
    "#              .config('spark.dynamicAllocation.enabled', False)\n",
    "         .config('spark.executorEnv.PYTHON_EGG_CACHE', '/tmp')\n",
    "#              .config('spark.executor.instances', 4)\n",
    "#              .config('spark.executor.cores', 13)\n",
    "#              .config('spark.executor.memory', '14g')\n",
    "         .config('spark.driver.memory', '7g')\n",
    "         .getOrCreate())\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as sf\n",
    "\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "Since we don't have an example of new incoming data we will separate into two dataframes. One as if it was the current data and another as the new ingestion data. I expect that there will be some overlapping operators, which is a realistic case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load current operator data and keep 5%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+------------------------+\n",
      "|ohubOperatorId                      |id                      |\n",
      "+------------------------------------+------------------------+\n",
      "|0935427a-dc99-4ae9-b9d2-bee072edf474|DK~DEX~10080940         |\n",
      "|0935427a-dc99-4ae9-b9d2-bee072edf474|DK~MM-INIT-OPER~O~622625|\n",
      "+------------------------------------+------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "operators_old_dir = 'adl://ulohubdldevne.azuredatalakestore.net/data/parquet/OPERATORS_MERGED.parquet'\n",
    "\n",
    "oprs_old = (\n",
    "    spark\n",
    "    .read.parquet(operators_old_dir)\n",
    "    .filter(sf.col('countryCode') == 'DK')\n",
    "    .sample(False, 0.05)\n",
    "    .withColumn('id', sf.explode(sf.col('refIds')))\n",
    "    .select('ohubOperatorId', 'id')\n",
    ")\n",
    "oprs_old.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get sample of source data 10%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read operators and assign id\n",
    "operators_matched_dir = 'adl://ulohubdldevne.azuredatalakestore.net/data/parquet/OPERATORS.parquet'\n",
    "\n",
    "input_oprs = (\n",
    "    spark\n",
    "    .read.parquet(operators_matched_dir)\n",
    "    .filter(sf.col('COUNTRY_CODE') == 'DK')\n",
    "    .sample(False, 0.1)\n",
    "    .withColumn('id', sf.concat_ws('~',\n",
    "                                   sf.col('COUNTRY_CODE'),\n",
    "                                   sf.col('SOURCE'),\n",
    "                                   sf.col('REF_OPERATOR_ID'))).select('id', 'NAME_CLEANSED')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New and overlapping operators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known Operators: 2002\n",
      "Input Operators: 4136\n",
      "Overlapping: 176\n",
      "New: 3960\n"
     ]
    }
   ],
   "source": [
    "df = input_oprs.join(oprs_old, on='id', how='left')\n",
    "\n",
    "print('Known Operators:', oprs_old.count())\n",
    "print('Input Operators:', input_oprs.count())\n",
    "print('Overlapping:', df.na.drop(subset=['ohubOperatorId']).count())\n",
    "print('New:', df.filter(sf.isnull(sf.col('ohubOperatorId'))).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create string name used originally for the matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DROP_CHARS = \"\\\\\\\\!#%&()*+-/:;<=>?@\\\\^|~\\u00A8\\u00A9\\u00AA\\u00AC\\u00AD\\u00AF\\u00B0\" \\\n",
    "             \"\\u00B1\\u00B2\\u00B3\\u00B6\\u00B8\\u00B9\\u00BA\\u00BB\\u00BC\\u00BD\\u00BE\" \\\n",
    "             \"\\u2013\\u2014\\u2022\\u2026\\u20AC\\u2121\\u2122\\u2196\\u2197\\u247F\\u250A\" \\\n",
    "             \"\\u2543\\u2605\\u2606\\u3001\\u3002\\u300C\\u300D\\u300E\\u300F\\u3010\\u3011\" \\\n",
    "             \"\\uFE36\\uFF01\\uFF06\\uFF08\\uFF09\\uFF1A\\uFF1B\\uFF1F{}\\u00AE\\u00F7\\u02F1\" \\\n",
    "             \"\\u02F3\\u02F5\\u02F6\\u02F9\\u02FB\\u02FC\\u02FD\\u1BFC\\u1BFD\\u2260\\u2264\" \\\n",
    "             \"\\u2DE2\\u2DF2\\uEC66\\uEC7C\\uEC7E\\uED2B\\uED34\\uED3A\\uEDAB\\uEDFC\\uEE3B\" \\\n",
    "             \"\\uEEA3\\uEF61\\uEFA2\\uEFB0\\uEFB5\\uEFEA\\uEFED\\uFDAB\\uFFB7\\u007F\\u24D2\" \\\n",
    "             \"\\u2560\\u2623\\u263A\\u2661\\u2665\\u266A\\u2764\\uE2B1\\uFF0D\"\n",
    "REGEX = \"[{}]\".format(DROP_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+------------+----------------------------+----------------------------------------------------------------------------+\n",
      "|ohubOperatorId                      |string_index|id                          |matching_string                                                             |\n",
      "+------------------------------------+------------+----------------------------+----------------------------------------------------------------------------+\n",
      "|1a7d6ece-83dd-41d0-860a-345555629f5a|0           |DK~COMPLAINTS~2503250       |unknown                                                                     |\n",
      "|602930a3-59b9-4910-8dfa-5cf2f9dab5c3|1           |DK~COMPLAINTS~OP_USD_5067_15|                                                                            |\n",
      "|97ad8b8b-8505-42df-b691-982e1dc02752|2           |DK~DEX~10001401             |boursin fromagerie su pacy sur eure croisysureure route de st aquilin3 27120|\n",
      "|3830d696-c16f-4039-badd-6b584de1aedd|3           |DK~DEX~10001764             |unilever ireland limited dublin riverwalk national digital park20 24        |\n",
      "|833753c9-a480-40e7-a95b-2c9aa2a401d5|4           |DK~DEX~10003032             |unilever slovenija doo ljubljana leskoskova cesta9e 1000                    |\n",
      "+------------------------------------+------------+----------------------------+----------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# at the moment only with Denmark\n",
    "\n",
    "w = Window.partitionBy('countryCode').orderBy(sf.asc('id'))\n",
    "\n",
    "operators_old = (\n",
    "    spark\n",
    "    .read.parquet(operators_old_dir)\n",
    "    .filter(sf.col('countryCode') == 'DK')\n",
    "    .withColumn('id', sf.col('operator').getItem('operatorConcatId'))\n",
    "    .withColumn('matching_string', sf.concat_ws(' ',\n",
    "                                                sf.col('operator').getItem('nameCleansed'),\n",
    "                                                sf.col('operator').getItem('cityCleansed'),\n",
    "                                                sf.col('operator').getItem('streetCleansed'),\n",
    "                                                sf.col('operator').getItem('zipCodeCleansed')))\n",
    "    .withColumn('matching_string', sf.regexp_replace('matching_string', REGEX, ''))\n",
    "    .withColumn('matching_string', sf.trim(sf.regexp_replace(sf.col('matching_string'), '\\s+', ' ')))\n",
    "    .withColumn('string_index', sf.row_number().over(w) - 1)\n",
    "    .select('ohubOperatorId', 'string_index','id', 'matching_string')\n",
    ")\n",
    "    \n",
    "operators_old.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|           SOURCE_ID|           TARGET_ID|         SOURCE_NAME|         TARGET_NAME|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|intet odder rudeh...|elev odder rudeha...|\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|æblehaven hillerø...|æblehaven 3400 tu...|\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|as storebælt kors...|sund bælt holding...|\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|ulvsund lave ikke...|        ulvsund 4780|\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|     sødisbakke 9550|     sødisbakke 9550|\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|    seb huset 2 1577|      seb hus 1 1577|\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|first hotel moles...|first hotel moles...|\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|   djurs mad is 8963|   djurs mad is 8963|\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|okæ madservice di...|okæ madservice di...|\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|  ceres centret 8700|  ceres centret 8700|\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|best western hote...|best western hote...|\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|alssundgymnasiet ...|alssundgymnasiet ...|\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|           teko 7400|           teko 7400|\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|det danske madhus...|det danske madhus...|\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|ibm danmark as so...|ibm danmark as so...|\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|palsgaard as juel...|palsgaard as juel...|\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|livgardens kasern...|livgardens kasern...|\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|landboforeningen ...|gefion 4180 fulby...|\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|cheval blanc serv...|cheval blanc serv...|\n",
      "|DK~mellowmessage~...|DK~mellowmessage~...|cheval blanc søbo...|cheval blanc søbo...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "operators_matched_dir = 'adl://ulohubdldevne.azuredatalakestore.net/data/parquet/OPERATORS_MATCHED.parquet'\n",
    "\n",
    "oprs_matched = spark.read.parquet(operators_matched_dir).filter(sf.col('COUNTRY_CODE') == 'DK').select('SOURCE_ID', 'TARGET_ID', 'SOURCE_NAME', 'TARGET_NAME')\n",
    "oprs_matched.sort('SOURCE_ID', ascending=False).show(20)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
