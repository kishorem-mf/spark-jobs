{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mocking data for ingestion job of operators\n",
    "\n",
    "For siplicity the code is written for only two countries: DK and NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "country_codes = {'DK', 'NL'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"NameMatching_Notebook\")\n",
    "    .config('spark.dynamicAllocation.enabled', False)\n",
    "    .config('spark.executorEnv.PYTHON_EGG_CACHE', '/tmp')\n",
    "    .config('spark.executor.instances', 4)\n",
    "    .config('spark.executor.cores', 13)\n",
    "    .config('spark.executor.memory', '14g')\n",
    "    .config('spark.driver.memory', '7g')\n",
    "    .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mock current operator data\n",
    "\n",
    "This will consist of only 5% of the current data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "operators_old_dir = 'adl://ulohubdldevne.azuredatalakestore.net/data/parquet/'\n",
    "test_output_dir = 'adl://ulohubdldevne.azuredatalakestore.net/data/parquet/test/'\n",
    "\n",
    "oprs_old = (spark\n",
    ".read.parquet(operators_old_dir + 'OPERATORS_MERGED.parquet')\n",
    ".sample(False, 0.05)\n",
    ".filter(sf.col('countryCode').isin(country_codes)))\n",
    "            \n",
    "(oprs_old\n",
    " .write\n",
    ".partitionBy('countryCode')\n",
    ".parquet(test_output_dir + 'OPERATORS_MERGED.parquet', mode='overwrite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark.read.parquet(test_output_dir + 'OPERATORS_MERGED.parquet').groupby('countryCode').count().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# needed for later steps to assess known operators in the input\n",
    "oprs_old = oprs_old.withColumn('id', sf.explode(sf.col('refIds')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mock input data as 1% from original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read operators and assign id\n",
    "operators_matched_dir = 'adl://ulohubdldevne.azuredatalakestore.net/data/parquet/'\n",
    "test_output_dir = 'adl://ulohubdldevne.azuredatalakestore.net/data/parquet/test/'\n",
    "\n",
    "input_oprs_raw = (spark\n",
    ".read.parquet(operators_matched_dir + 'OPERATORS.parquet')\n",
    ".sample(False, 0.01)\n",
    ".filter(sf.col('COUNTRY_CODE').isin(country_codes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for overlap and alter some records**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_oprs = (\n",
    "    input_oprs_raw\n",
    "    .withColumn('id', sf.concat_ws('~',\n",
    "                                   sf.col('COUNTRY_CODE'),\n",
    "                                   sf.col('SOURCE'),\n",
    "                                   sf.col('REF_OPERATOR_ID')))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oprs = input_oprs.join(oprs_old, on='id', how='left')\n",
    "# 15% of the already known operators will be altered on the `STREET_CLEANSED`\n",
    "oprs = df.withColumn('STREET_CLEANSED', sf.when(sf.col('ohubOperatorId').isNotNull() & (sf.rand(seed=0) < 0.15), 'street_changed').otherwise(sf.col('STREET_CLEANSED')))\n",
    "# assign column with the type of incoming operator record: known changed, known unchanged, new\n",
    "oprs = (df_altered\n",
    " .withColumn('record_type',\n",
    "             sf.when(sf.col('ohubOperatorId').isNotNull() & (sf.col('STREET_CLEANSED').isNull() | (sf.col('STREET_CLEANSED') != 'street_changed')), 'known_unchanged')\n",
    "             .when(sf.col('ohubOperatorId').isNotNull() & (sf.col('STREET_CLEANSED') == 'street_changed'), 'known_changed')\n",
    "             .when(sf.col('ohubOperatorId').isNull(), 'new'))\n",
    ")\n",
    "oprs.persist()\n",
    "oprs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if oprs.count() != oprs.dropna(subset=['record_type']).count():\n",
    "    raise ValueError(\"There are some NULL values in record_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ohub known Operators: Operators already grouped and in the Ohub data storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oprs_old.groupby('countryCode').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input operators: incoming data of operators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oprs.groupby('COUNTRY_CODE').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Known: incoming operator data already in Ohub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oprs.filter(sf.col('record_type').isin({'known_unchanged', 'known_changed'})).groupby('COUNTRY_CODE').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Known unchanged: incoming operator data already in Ohub with no change in its data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oprs.filter(sf.col('record_type') == 'known_unchanged').groupby('COUNTRY_CODE').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Known Changed: incoming operator data already in Ohub with change in its data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oprs.filter(sf.col('record_type') == 'known_changed').groupby('COUNTRY_CODE').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input New: Completely new operator data (id not in Ohub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oprs.filter(sf.col('record_type') == 'new').groupby('COUNTRY_CODE').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write mocked input operator data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(oprs\n",
    " .select(input_oprs_raw.columns + ['record_type'])\n",
    " .write\n",
    " .partitionBy('COUNTRY_CODE')\n",
    " .parquet(test_output_dir + 'OPERATORS.parquet', mode='overwrite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark.read.parquet(test_output_dir + 'OPERATORS.parquet').groupby('COUNTRY_CODE').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
