
pipelines:
  default:
    - step:
        name: Check PEP8 codestyle and run tests
        image: fokkodriesprong/docker-pyspark
        script:
          - conda env create -f environment.yml
          - source activate name-matching
          - pycodestyle --show-source .
          - cd string_matching_package
          - python setup.py pytest --addopts "--cov-config .coveragerc --cov=./ tests"
  branches:
    master:
    - step:
        image: fokkodriesprong/docker-pyspark
        script:
          - conda env create -f environment.yml
          - source activate name-matching
          - pycodestyle --show-source .
          - cd string_matching_package
          - python setup.py pytest --addopts "--cov-config .coveragerc --cov=./ tests"
    - step:
        name: Build EGG
        image: timvancann/miniconda3-gcc
        script:
          - conda env create -f environment.yml
          - source activate name-matching
          - ./compile_library.sh
        artifacts:
          - dist/*.egg
    - step:
        name: Deploy to databricks fs
        image: timvancann/databricks-cli
        deployment: production
        script:
          - touch ~/.databrickscfg
          - echo "[DEFAULT]" >> ~/.databrickscfg
          - echo "host = ${DB_HOST}" >> ~/.databrickscfg
          - echo "token = ${DB_TOKEN}" >> ~/.databrickscfg
          - cat ~/.databrickscfg

          - databricks fs cp --overwrite dist/string_matching.egg dbfs:/libraries/name_matching/string_matching.egg
          - databricks fs cp --overwrite string_matching_package/match_operators.py dbfs:/libraries/name_matching/match_operators.py
          - databricks fs cp --overwrite string_matching_package/match_contacts.py dbfs:/libraries/name_matching/match_contacts.py
          - databricks fs cp --overwrite string_matching_package/delta_operators.py dbfs:/libraries/name_matching/delta_operators.py

